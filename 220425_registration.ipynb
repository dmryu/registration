{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f70f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from registrator import Registrator\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cf6ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### padding for square-shaped image generation\n",
    "def fit_to_square_bf(img):\n",
    "    y, x, _ = img.shape\n",
    "\n",
    "    # fit to even numbers\n",
    "    if y%2 != 0:\n",
    "        img = np.pad(img, [(1, 0), (0, 0), (0, 0)], mode='maximum')\n",
    "    elif x%2 != 0:\n",
    "        img = np.pad(img, [(0, 0), (1, 0), (0, 0)], mode='maximum')\n",
    "\n",
    "    # padding\n",
    "    pad = abs(y-x) // 2\n",
    "    img = np.pad(img, ((0, 0), (pad, pad), (0, 0)), mode='maximum') if y > x else np.pad(img, ((pad, pad), (0, 0), (0, 0)), mode='maximum')\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def fit_to_square_ri(img):\n",
    "    y, x= img.shape\n",
    "\n",
    "    # fit to even numbers\n",
    "    if y%2 != 0:\n",
    "        img = np.pad(img, [(1, 0), (0, 0)], mode='minimum')\n",
    "    elif x%2 != 0:\n",
    "        img = np.pad(img, [(0, 0), (1, 0)], mode='minimum')\n",
    "\n",
    "    # padding\n",
    "    pad = abs(y-x) // 2\n",
    "    img = np.pad(img, ((0, 0), (pad, pad)), mode='minimum') if y > x else np.pad(img, ((pad, pad), (0, 0)), mode='minimum')\n",
    "\n",
    "    return img\n",
    "\n",
    "### image simplifying\n",
    "def simplifying(img, type='BF', thres=245):\n",
    "    if type=='BF':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        thres = (img < thres).astype(np.uint8)\n",
    "    elif type=='RI':\n",
    "        thres = (img > thres).astype(np.uint8)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    kernel2 = np.ones((6, 6), np.uint8)\n",
    "\n",
    "    closing = cv2.morphologyEx(thres.astype(np.uint8), cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel2, iterations=1)\n",
    "\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f8c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "# samples which have stitched images\n",
    "data_path = Path('/data4/NCC/dataset/NCC_missing')\n",
    "stitched_ris = sorted(data_path.rglob('*Stitching.TCF'))\n",
    "stitched_bfs = sorted(data_path.rglob('*Stitching000000BF.PNG'))\n",
    "\n",
    "\n",
    "# samples which do not have stitched images (single FOV images)\n",
    "temp = sorted(data_path.glob('*/*P20*'))\n",
    "single_paths = [x for x in temp \n",
    "              if x.is_dir() is True \n",
    "              and 'T' not in x.name]\n",
    "single_ris = [sorted(x.rglob('*.TCF'))[0] for x in single_paths]\n",
    "single_bfs = [sorted(x.rglob('*BF.PNG'))[0] for x in single_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78931d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d9054f88e341b08bf92f209d95d5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 380)\n"
     ]
    }
   ],
   "source": [
    "# Registration Loop\n",
    "for i, paths in enumerate(tqdm(zip(single_ris, single_bfs), total=len(single_ris))):\n",
    "    with h5py.File(paths[0], 'r') as f:\n",
    "        ri = f['Data/2DMIP/000000'][()]\n",
    "    bf = np.asarray(Image.open(paths[1]))\n",
    "    \n",
    "    # resizing\n",
    "    bf = fit_to_square_bf(bf)\n",
    "    ri = fit_to_square_ri(ri)\n",
    "    \n",
    "    bf = cv2.resize(bf, dsize=ri.shape, interpolation=cv2.INTER_LINEAR)\n",
    "    bf = cv2.cvtColor(bf, cv2.COLOR_RGB2GRAY)\n",
    "    bf = np.expand_dims(bf, 2)\n",
    "    ri = np.expand_dims(ri, 2)\n",
    "    \n",
    "    lr = 0.01\n",
    "    loss = \"mse\"\n",
    "    num_epochs = 400\n",
    "    registrator = Registrator(\n",
    "        lr=lr, loss=loss, in_chans=1, num_epochs=num_epochs, device=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1389c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
